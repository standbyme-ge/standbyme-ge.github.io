<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yrs-SWUST</title>
  
  <meta name="author" content="Yrs">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jon Barron</name>
              </p>
              <p>I am a senior staff research scientist at <a href="https://ai.google/research">Google Research</a>, where I work on computer vision and machine learning.
              </p>
              <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/jonbarron/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="blocknerf_stop()" onmouseover="blocknerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='blocknerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/blocknerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/blocknerf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function blocknerf_start() {
                  document.getElementById('blocknerf_image').style.opacity = "1";
                }

                function blocknerf_stop() {
                  document.getElementById('blocknerf_image').style.opacity = "0";
                }
                blocknerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://waymo.com/research/block-nerf/">
                <papertitle>Block-NeRF: Scalable Large Scene Neural View Synthesis</papertitle>
              </a>
              <br>
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <a href="http://casser.io/">Vincent Casser</a>,
              <a href="https://sites.google.com/site/skywalkeryxc/">Xinchen Yan</a>,
              <a href="https://scholar.google.com/citations?user=5mJUkI4AAAAJ&hl=en">Sabeek Pradhan</a>, <br>
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
							<a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://sites.google.com/corp/view/kretzschmar/">Henrik Kretzschmar</a>
              <br>
        <em>CVPR</em>, 2022
              <br>
              <a href="https://waymo.com/research/block-nerf/">project page</a>
        /
              <a href="https://arxiv.org/abs/2202.05263">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=6lGMCAzBzOQ">video</a>
              <p></p>
              <p>We can do city-scale reconstruction by training multiple NeRFs with millions of images.</p>
            </td>
          </tr>
         </td>
    </tr>
  </table>
</body>

</html>
